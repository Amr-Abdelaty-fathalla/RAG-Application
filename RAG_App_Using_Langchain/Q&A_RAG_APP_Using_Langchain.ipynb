{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RAG System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create RAG System to answer questions from pdf document using ollama and langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store document name in variable\n",
    "PDF_FILE = 'paul.pdf'\n",
    "\n",
    "# use llama 3.1 \n",
    "MODEL = 'llama3.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 9\n",
      "Length of a page: 3272\n",
      "Content of a page: 10% a week. And while 110 may not seem much better than 100,\n",
      "if you keep growing at 10% a week you'll be surprised how big\n",
      "the numbers get. After a year you'll have 14,000 users, and after\n",
      "2 years you'll have 2 million.\n",
      "You'll be doing different things when you're acquiring users a\n",
      "thousand at a time, and growth has to slow down eventually. But\n",
      "if the market exists you can usually start by recruiting users\n",
      "manually and then gradually switch to less manual methods. [3]\n",
      "Airbnb is a classic example of this technique. Marketplaces are so\n",
      "hard to get rolling that you should expect to take heroic measures\n",
      "at first. In Airbnb's case, these consisted of going door to door in\n",
      "New York, recruiting new users and helping existing ones improve\n",
      "their listings. When I remember the Airbnbs during YC, I picture\n",
      "them with rolly bags, because when they showed up for tuesday\n",
      "dinners they'd always just flown back from somewhere.\n",
      "Fragile\n",
      "Airbnb now seems like an unstoppable juggernaut, but early on it\n",
      "was so fragile that about 30 days of going out and engaging in\n",
      "person with users made the difference between success and\n",
      "failure.\n",
      "That initial fragility was not a unique feature of Airbnb. Almost all\n",
      "startups are fragile initially. And that's one of the biggest things\n",
      "inexperienced founders and investors (and reporters and know-it-\n",
      "alls on forums) get wrong about them. They unconsciously judge\n",
      "larval startups by the standards of established ones. They're like\n",
      "someone looking at a newborn baby and concluding \"there's no\n",
      "way this tiny creature could ever accomplish anything.\"\n",
      "It's harmless if reporters and know-it-alls dismiss your startup.\n",
      "They always get things wrong. It's even ok if investors dismiss\n",
      "your startup; they'll change their minds when they see growth.\n",
      "The big danger is that you'll dismiss your startup yourself. I've\n",
      "seen it happen. I often have to encourage founders who don't see\n",
      "the full potential of what they're building. Even Bill Gates made\n",
      "that mistake. He returned to Harvard for the fall semester after\n",
      "starting Microsoft. He didn't stay long, but he wouldn't have\n",
      "returned at all if he'd realized Microsoft was going to be even a\n",
      "fraction of the size it turned out to be. [4]\n",
      "The question to ask about an early stage startup is not \"is this\n",
      "company taking over the world?\" but \"how big could this company\n",
      "get if the founders did the right things?\" And the right things\n",
      "often seem both laborious and inconsequential at the time.\n",
      "Microsoft can't have seemed very impressive when it was just a\n",
      "couple guys in Albuquerque writing Basic interpreters for a\n",
      "market of a few thousand hobbyists (as they were then called),\n",
      "but in retrospect that was the optimal path to dominating\n",
      "microcomputer software. And I know Brian Chesky and Joe\n",
      "Gebbia didn't feel like they were en route to the big time as they\n",
      "were taking \"professional\" photos of their first hosts' apartments.\n",
      "They were just trying to survive. But in retrospect that too was\n",
      "the optimal path to dominating a big market.\n",
      "How do you find users to recruit manually? If you build something\n",
      "to solve your own problems, then you only have to find your\n",
      "peers, which is usually straightforward. Otherwise you'll have to\n",
      "8/6/24, 11:04 AM Do Things that Don't Scale\n",
      "https://paulgraham.com/ds.html 2/9\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(PDF_FILE)\n",
    "pages = loader.load()\n",
    "\n",
    "print(f'Number of pages: {len(pages)}')\n",
    "print(f'Length of a page: {len(pages[1].page_content)}')\n",
    "print(f'Content of a page: {pages[1].page_content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the pages into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:23\n",
      "Length of a chunk:1236\n",
      "Content of a chunck :took better advantage of it than Stripe. At YC we use the term\n",
      "\"Collison installation\" for the technique they invented. More\n",
      "diffident founders ask \"Will you try our beta?\" and if the answer is\n",
      "yes, they say \"Great, we'll send you a link.\" But the Collison\n",
      "brothers weren't going to wait. When anyone agreed to try Stripe\n",
      "they'd say \"Right then, give me your laptop\" and set them up on\n",
      "the spot.\n",
      "There are two reasons founders resist going out and recruiting\n",
      "users individually. One is a combination of shyness and laziness.\n",
      "They'd rather sit at home writing code than go out and talk to a\n",
      "bunch of strangers and probably be rejected by most of them.\n",
      "But for a startup to succeed, at least one founder (usually the\n",
      "CEO) will have to spend a lot of time on sales and marketing. [2]\n",
      "The other reason founders ignore this path is that the absolute\n",
      "numbers seem so small at first. This can't be how the big, famous\n",
      "startups got started, they think. The mistake they make is to\n",
      "underestimate the power of compound growth. We encourage\n",
      "every startup to measure their progress by weekly growth rate. If\n",
      "you have 100 users, you need to get 10 more next week to grow\n",
      "8/6/24, 11:04 AM Do Things that Don't Scale\n",
      "https://paulgraham.com/ds.html 1/9\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1500, chunk_overlap = 100)\n",
    "chunks = splitter.split_documents(pages)\n",
    "\n",
    "print(f'Number of chunks:{len(chunks)}')\n",
    "print(f'Length of a chunk:{len(chunks[1].page_content)}')\n",
    "print(f'Content of a chunck :{chunks[1].page_content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the chunks in a vector store after generate embedding for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1752/3573475093.py:4: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model = MODEL)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OllamaEmbeddings(model = MODEL)\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='35b01d71-3bb5-4585-9c2b-a50c1253cba2', metadata={'source': 'paul.pdf', 'page': 4, 'page_label': '5'}, page_content='You can tweak the design faster when you\\'re the factory, and you\\nlearn things you\\'d never have known otherwise. Eric Migicovsky\\nof Pebble said one of the things he learned was \"how valuable it\\nwas to source good screws.\" Who knew?\\nConsult\\n8/6/24, 11:04 AM Do Things that Don\\'t Scale\\nhttps://paulgraham.com/ds.html 5/9'),\n",
       " Document(id='082ae8bd-6214-4c29-9d36-d176b093f6ab', metadata={'source': 'paul.pdf', 'page': 7, 'page_label': '8'}, page_content='by calibrating their ambitions, because we know exactly how a lot\\nof successful startups looked when they were just getting started.\\n[5] If you\\'re building something for which you can\\'t easily get a\\nsmall set of users to observe — e.g. enterprise software — and in\\na domain where you have no connections, you\\'ll have to rely on\\ncold calls and introductions. But should you even be working on\\nsuch an idea?\\n[6] Garry Tan pointed out an interesting trap founders fall into in\\nthe beginning. They want so much to seem big that they imitate\\neven the flaws of big companies, like indifference to individual\\nusers. This seems to them more \"professional.\" Actually it\\'s better\\nto embrace the fact that you\\'re small and use whatever\\nadvantages that brings.\\n[7] Your user model almost couldn\\'t be perfectly accurate,\\nbecause users\\' needs often change in response to what you build\\nfor them. Build them a microcomputer, and suddenly they need to\\nrun spreadsheets on it, because the arrival of your new\\nmicrocomputer causes someone to invent the spreadsheet.\\n[8] If you have to choose between the subset that will sign up\\nquickest and those that will pay the most, it\\'s usually best to pick\\nthe former, because those are probably the early adopters. They\\'ll\\n8/6/24, 11:04 AM Do Things that Don\\'t Scale\\nhttps://paulgraham.com/ds.html 8/9'),\n",
       " Document(id='402ca895-71cb-45e1-bbc4-03303c3acc41', metadata={'source': 'paul.pdf', 'page': 2, 'page_label': '3'}, page_content=\"of service no big company can. [6]\\nOnce you realize that existing conventions are not the upper\\nbound on user experience, it's interesting in a very pleasant way\\nto think about how far you could go to delight your users.\\n8/6/24, 11:04 AM Do Things that Don't Scale\\nhttps://paulgraham.com/ds.html 3/9\"),\n",
       " Document(id='52b90318-c181-4510-884b-20e486b065b8', metadata={'source': 'paul.pdf', 'page': 6, 'page_label': '7'}, page_content=\"in general, but they especially don't work as a way to get growth\\nstarted. It's a common mistake among inexperienced founders to\\nbelieve that a partnership with a big company will be their big\\nbreak. Six months later they're all saying the same thing: that\\nwas way more work than we expected, and we ended up getting\\npractically nothing out of it. [11]\\nIt's not enough just to do something extraordinary initially. You\\nhave to make an extraordinary effort initially. Any strategy that\\nomits the effort — whether it's expecting a big launch to get you\\nusers, or a big partner — is ipso facto suspect.\\nVector\\nThe need to do something unscalably laborious to get started is\\nso nearly universal that it might be a good idea to stop thinking\\nof startup ideas as scalars. Instead we should try thinking of\\nthem as pairs of what you're going to build, plus the unscalable\\nthing(s) you're going to do initially to get the company going.\\nIt could be interesting to start viewing startup ideas this way,\\nbecause now that there are two components you can try to be\\nimaginative about the second as well as the first. But in most\\ncases the second component will be what it usually is — recruit\\nusers manually and give them an overwhelmingly good\\nexperience — and the main benefit of treating startups as vectors\\nwill be to remind founders they need to work hard in two\\ndimensions. [12]\\nIn the best case, both components of the vector contribute to\\nyour company's DNA: the unscalable things you have to do to get\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how can i get data from my vector store ==> retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke('What can you get away with when you only have a small number of users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As of my last update in April 2023, Joe Biden is the President of the United States. He was inaugurated as the 46th President on January 20, 2021. However, please note that this information may change over time due to elections or other events.\\n\\nIf you're looking for more up-to-date information, I recommend checking a reliable news source or official government website for the most current information on the presidency.\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-02-04T04:41:22.308608007Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5007656168, 'load_duration': 2516157144, 'prompt_eval_count': 18, 'prompt_eval_duration': 148000000, 'eval_count': 90, 'eval_duration': 2342000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-9c309dd2-6982-4216-9da9-12ef9f8a6360-0', usage_metadata={'input_tokens': 18, 'output_tokens': 90, 'total_tokens': 108})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model = MODEL, temperature = 0)\n",
    "model.invoke('who is the president of the United States')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chain and add model & parser to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in April 2023, Joe Biden is the President of the United States. He was inaugurated as the 46th President on January 20, 2021. However, please note that this information may change over time due to elections or other events.\n",
      "\n",
      "If you're looking for more up-to-date information, I recommend checking a reliable news source or official government website for the most current information on the presidency.\n"
     ]
    }
   ],
   "source": [
    "# i want to to get rid of AI Message and get my answer as string so we will use string output parser in langchain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n",
    "\n",
    "print(chain.invoke('who is the president of the United States'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a prompt (question & context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an assistant that provides answers to questions based on\n",
      "a given context. \n",
      "\n",
      "Answer the question based on the context. If you can't answer the\n",
      "question, reply \"I don't know\".\n",
      "\n",
      "Be as concise as possible and go straight to the point.\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets create our prompt template\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an assistant that provides answers to questions based on\n",
    "a given context. \n",
    "\n",
    "Answer the question based on the context. If you can't answer the\n",
    "question, reply \"I don't know\".\n",
    "\n",
    "Be as concise as possible and go straight to the point.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# show our prompt template\n",
    "print(prompt.format(context = 'Here is some context', question = 'Here is a question'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Prompt to the chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amr.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "\n",
    "# test our chain works fine\n",
    "chain.invoke({\n",
    "    'context' : 'Amr\\'s brother is medhat',\n",
    "    'question' : 'who is medhat\\'s brother?'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the retriever to the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding retriever to the chain\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\" : itemgetter('question') | retriever,\n",
    "        \"question\" : itemgetter('question')\n",
    "    }\n",
    "| prompt\n",
    "| model\n",
    "| parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the chain to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What can you get away with when you only have a small number of users?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers: You can provide a level of service no big company can.\n",
      "************************************************************\n",
      "Question: What's the most common unscalable thing founders have to do at the start?\n",
      "Answers: Going out and recruiting users individually.\n",
      "************************************************************\n",
      "Question: What's one of the biggest things inexperienced founders and investors get wrong about startups?\n",
      "Answers: They underestimate the power of compound growth.\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What can you get away with when you only have a small number of users?\",\n",
    "    \"What's the most common unscalable thing founders have to do at the start?\",\n",
    "    \"What's one of the biggest things inexperienced founders and investors get wrong about startups?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "       print(f\"Question: {question}\") \n",
    "       print(f\"Answers: {chain.invoke({'question':question})}\") \n",
    "       print('*' * 60) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
